{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7d4fd7-f378-49f0-bae8-1f48f0da987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data appended to processed_aqi_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "AQICN_API_KEY = \"3ab568459364d9a295405394a113823df31a9a82\"\n",
    "OPENWEATHER_API_KEY = \"c78b17200559431652d643ad3e0259a9\"\n",
    "\n",
    "CITY = \"Karachi\"\n",
    "\n",
    "# Fetch AQICN data\n",
    "def fetch_aqicn_data(city):\n",
    "    url = f\"https://api.waqi.info/feed/{city}/?token={AQICN_API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"ok\":\n",
    "            return {\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"aqi\": data[\"data\"][\"aqi\"],\n",
    "                \"dominant_pollutant\": data[\"data\"][\"dominentpol\"]\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# Fetch OpenWeather data\n",
    "def fetch_openweather_data(city):\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Fetch combined data\n",
    "def fetch_combined_data(city):\n",
    "    aqi_data = fetch_aqicn_data(city)\n",
    "    weather_data = fetch_openweather_data(city)\n",
    "    if aqi_data and weather_data:\n",
    "        return {**aqi_data, **weather_data}\n",
    "    return None\n",
    "\n",
    "# Generate time-based features\n",
    "def add_time_features(df):\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['season'] = df['month'] % 12 // 3 + 1  # 1: Winter, 2: Spring, etc.\n",
    "    return df\n",
    "\n",
    "# Generate derived features\n",
    "def add_derived_features(df):\n",
    "    df['aqi_change_rate'] = df['aqi'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # AQI/hour\n",
    "    df['temp_change_rate'] = df['temperature'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # °C/hour\n",
    "    df['humidity_change_rate'] = df['humidity'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # %/hour\n",
    "    return df\n",
    "\n",
    "# Define target (e.g., next AQI)\n",
    "def add_targets(df):\n",
    "    df['target_aqi'] = df['aqi'].shift(-1)  # Next AQI value\n",
    "    return df\n",
    "\n",
    "# Main function to fetch, process, and generate features\n",
    "def main():\n",
    "    raw_data = []\n",
    "    # Collect 10 samples with a delay to simulate a time series\n",
    "    for _ in range(10):\n",
    "        data = fetch_combined_data(CITY)\n",
    "        if data:\n",
    "            raw_data.append(data)\n",
    "        time.sleep(60)  # Wait 60 seconds between API calls\n",
    "\n",
    "    # Convert raw data to DataFrame\n",
    "    df = pd.DataFrame(raw_data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Compute features and targets\n",
    "    df = add_time_features(df)\n",
    "    df = add_derived_features(df)\n",
    "    df = add_targets(df)\n",
    "\n",
    "    # Drop rows with NaN (from diff or shift operations)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Save the processed DataFrame to a CSV file\n",
    "    output_file = \"processed_aqi_weather_data.csv\"\n",
    "    file_exists = os.path.isfile(output_file)\n",
    "    df.to_csv(output_file, mode='a', header=not file_exists, index=False)\n",
    "    print(f\"Processed data appended to {output_file}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d14c6a7-a984-4534-b6d5-e8d5ab7a91f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emad_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-20 22:29:44,189 INFO: Initializing external client\n",
      "2025-01-20 22:29:44,189 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-20 22:30:01,020 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1200282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ploading Dataframe: 100.00% |█████████████████████████████████| Rows 8/8 | Elapsed Time: 00:02 | Remaining Time: 00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: aqi_weather_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1200282/jobs/named/aqi_weather_features_1_offline_fg_materialization/executions\n",
      "Features successfully inserted into Hopsworks Feature Store.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import hopsworks\n",
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "# Replace with your API keys\n",
    "AQICN_API_KEY = \"3ab568459364d9a295405394a113823df31a9a82\"\n",
    "OPENWEATHER_API_KEY = \"c78b17200559431652d643ad3e0259a9\"\n",
    "\n",
    "# Example location\n",
    "CITY = \"Karachi\"\n",
    "\n",
    "# Fetch AQICN data\n",
    "def fetch_aqicn_data(city):\n",
    "    url = f\"https://api.waqi.info/feed/{city}/?token={AQICN_API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"ok\":\n",
    "            return {\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"aqi\": data[\"data\"][\"aqi\"],\n",
    "                \"dominant_pollutant\": data[\"data\"][\"dominentpol\"]\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# Fetch OpenWeather data\n",
    "def fetch_openweather_data(city):\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Fetch combined data\n",
    "def fetch_combined_data(city):\n",
    "    aqi_data = fetch_aqicn_data(city)\n",
    "    weather_data = fetch_openweather_data(city)\n",
    "    if aqi_data and weather_data:\n",
    "        return {**aqi_data, **weather_data}\n",
    "    return None\n",
    "\n",
    "# Generate time-based features\n",
    "def add_time_features(df):\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['season'] = df['month'] % 12 // 3 + 1  # 1: Winter, 2: Spring, etc.\n",
    "    return df\n",
    "\n",
    "# Generate derived features\n",
    "def add_derived_features(df):\n",
    "    df['aqi_change_rate'] = df['aqi'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # AQI/hour\n",
    "    df['temp_change_rate'] = df['temperature'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # °C/hour\n",
    "    df['humidity_change_rate'] = df['humidity'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # %/hour\n",
    "    return df\n",
    "\n",
    "# Define target (e.g., next AQI)\n",
    "def add_targets(df):\n",
    "    df['target_aqi'] = df['aqi'].shift(-1)  # Next AQI value\n",
    "    return df\n",
    "\n",
    "# Main function to fetch, process, and save data to Feature Store\n",
    "def main():\n",
    "    raw_data = []\n",
    "\n",
    "    # Collect 10 samples with a delay to simulate a time series\n",
    "    for _ in range(10):\n",
    "        data = fetch_combined_data(CITY)\n",
    "        if data:\n",
    "            raw_data.append(data)\n",
    "        time.sleep(60)  # Wait 60 seconds between API calls\n",
    "\n",
    "    # Convert raw data to DataFrame\n",
    "    df = pd.DataFrame(raw_data)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Keep as datetime for feature generation\n",
    "\n",
    "    # Compute features and targets\n",
    "    df = add_time_features(df)\n",
    "    df = add_derived_features(df)\n",
    "    df = add_targets(df)\n",
    "\n",
    "    # Convert timestamp to string for compatibility with Hopsworks\n",
    "    df['timestamp'] = df['timestamp'].astype(str)\n",
    "\n",
    "    # Drop rows with NaN (from diff or shift operations)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Connect to Hopsworks\n",
    "    project = hopsworks.login(api_key_value=\"NzKsbygmeyP444mJ.xIpih1OWQwPuer5J6bFSo6wDCiTrPLsiMdk8l1ErXL77cuxMEkQ9tM0z2ambpVqy\")\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    # Define the feature group\n",
    "    feature_group = fs.get_or_create_feature_group(\n",
    "        name=\"aqi_weather_features\",\n",
    "        version=1,\n",
    "        description=\"AQI and weather data with derived and target features\",\n",
    "        primary_key=[\"timestamp\"],\n",
    "        online_enabled=True\n",
    "    )\n",
    "\n",
    "    # Save the DataFrame to the Feature Store\n",
    "    feature_group.insert(df)\n",
    "    print(\"Features successfully inserted into Hopsworks Feature Store.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fcba11f-638a-40c0-92ba-0d8117a6f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 0, 57, 431889), 'aqi': 174, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 0, 57, 854419), 'temperature': 15.9, 'humidity': 39}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 1, 59, 241118), 'aqi': 174, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 2, 0, 161690), 'temperature': 15.9, 'humidity': 39}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 3, 0, 771651), 'aqi': 174, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 3, 1, 277155), 'temperature': 15.9, 'humidity': 39}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 4, 1, 933461), 'aqi': 174, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 4, 2, 322731), 'temperature': 15.9, 'humidity': 39}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 5, 2, 997455), 'aqi': 174, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 5, 3, 397203), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 6, 4, 23492), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 6, 4, 398910), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 7, 5, 85850), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 7, 5, 498368), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 8, 6, 382111), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 8, 7, 60063), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 9, 7, 719437), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 9, 8, 141638), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 10, 8, 753720), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 10, 9, 353200), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 11, 10, 30350), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 11, 10, 433431), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 12, 11, 127720), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 12, 11, 539882), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 13, 13, 280662), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 13, 13, 910376), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 14, 16, 210675), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 14, 17, 490614), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 15, 19, 260661), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 15, 19, 708816), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 16, 20, 623362), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 16, 21, 608417), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 17, 22, 444548), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 17, 23, 541562), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 18, 25, 358456), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 18, 25, 801325), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 19, 26, 938629), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 19, 27, 732740), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 20, 28, 892656), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 20, 29, 747331), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 21, 30, 467777), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 21, 30, 977325), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 22, 31, 732072), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 22, 32, 388933), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 23, 36, 29580), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 23, 36, 992150), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 24, 38, 854), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 24, 38, 660128), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 25, 39, 349660), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 25, 40, 102709), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 26, 40, 954865), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 26, 41, 820977), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 27, 44, 61959), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 27, 44, 544662), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 28, 45, 770208), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 28, 46, 507707), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 29, 47, 215951), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 29, 47, 732267), 'temperature': 14.9, 'humidity': 41}\n",
      "AQI Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 30, 48, 505792), 'aqi': 211, 'dominant_pollutant': 'pm25'}\n",
      "Weather Data: {'timestamp': datetime.datetime(2025, 1, 20, 23, 30, 48, 975889), 'temperature': 14.9, 'humidity': 41}\n",
      "Raw data collected: [{'timestamp': datetime.datetime(2024, 12, 21, 23, 0, 56, 588854), 'aqi': 174, 'dominant_pollutant': 'pm25', 'temperature': 15.9, 'humidity': 39}, {'timestamp': datetime.datetime(2024, 12, 22, 23, 0, 56, 588854), 'aqi': 174, 'dominant_pollutant': 'pm25', 'temperature': 15.9, 'humidity': 39}, {'timestamp': datetime.datetime(2024, 12, 23, 23, 0, 56, 588854), 'aqi': 174, 'dominant_pollutant': 'pm25', 'temperature': 15.9, 'humidity': 39}, {'timestamp': datetime.datetime(2024, 12, 24, 23, 0, 56, 588854), 'aqi': 174, 'dominant_pollutant': 'pm25', 'temperature': 15.9, 'humidity': 39}, {'timestamp': datetime.datetime(2024, 12, 25, 23, 0, 56, 588854), 'aqi': 174, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2024, 12, 26, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2024, 12, 27, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2024, 12, 28, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2024, 12, 29, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2024, 12, 30, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2024, 12, 31, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 1, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 2, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 3, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 4, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 5, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 6, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 7, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 8, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 9, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 10, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 11, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 12, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 13, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 14, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 15, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 16, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 17, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 18, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}, {'timestamp': datetime.datetime(2025, 1, 19, 23, 0, 56, 588854), 'aqi': 211, 'dominant_pollutant': 'pm25', 'temperature': 14.9, 'humidity': 41}]\n",
      "2025-01-20 23:31:50,459 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-20 23:31:51,530 INFO: Initializing external client\n",
      "2025-01-20 23:31:51,530 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-20 23:31:57,427 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1200282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ploading Dataframe: 100.00% |███████████████████████████████| Rows 28/28 | Elapsed Time: 00:03 | Remaining Time: 00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: aqi_weather_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1200282/jobs/named/aqi_weather_features_1_offline_fg_materialization/executions\n",
      "Features successfully inserted into Hopsworks Feature Store.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import hopsworks\n",
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "# Replace with your API keys\n",
    "AQICN_API_KEY = \"3ab568459364d9a295405394a113823df31a9a82\"\n",
    "OPENWEATHER_API_KEY = \"c78b17200559431652d643ad3e0259a9\"\n",
    "\n",
    "# Example location\n",
    "CITY = \"Karachi\"\n",
    "\n",
    "# Fetch AQICN data\n",
    "def fetch_aqicn_data(city):\n",
    "    url = f\"https://api.waqi.info/feed/{city}/?token={AQICN_API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"ok\":\n",
    "            return {\n",
    "                \"timestamp\": datetime.now(),  # Temporary placeholder; update later\n",
    "                \"aqi\": data[\"data\"][\"aqi\"],\n",
    "                \"dominant_pollutant\": data[\"data\"][\"dominentpol\"]\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# Fetch OpenWeather data\n",
    "def fetch_openweather_data(city):\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"timestamp\": datetime.now(),  # Temporary placeholder; update later\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Fetch combined data for a specific date\n",
    "def fetch_combined_data(city, date):\n",
    "    aqi_data = fetch_aqicn_data(city)\n",
    "    weather_data = fetch_openweather_data(city)\n",
    "    \n",
    "    if aqi_data:\n",
    "        print(\"AQI Data:\", aqi_data)  # Debugging output for AQI data\n",
    "    else:\n",
    "        print(\"Failed to fetch AQI data for date:\", date)\n",
    "\n",
    "    if weather_data:\n",
    "        print(\"Weather Data:\", weather_data)  # Debugging output for weather data\n",
    "    else:\n",
    "        print(\"Failed to fetch weather data for date:\", date)\n",
    "\n",
    "    if aqi_data and weather_data:\n",
    "        combined_data = {**aqi_data, **weather_data}\n",
    "        combined_data['timestamp'] = date  # Use the date passed to the function\n",
    "        return combined_data\n",
    "    return None\n",
    "\n",
    "# Generate time-based features\n",
    "def add_time_features(df):\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['season'] = df['month'] % 12 // 3 + 1  # 1: Winter, 2: Spring, etc.\n",
    "    return df\n",
    "\n",
    "# Generate derived features\n",
    "def add_derived_features(df):\n",
    "    df['aqi_change_rate'] = df['aqi'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # AQI/hour\n",
    "    df['temp_change_rate'] = df['temperature'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # °C/hour\n",
    "    df['humidity_change_rate'] = df['humidity'].diff() / df['timestamp'].diff().dt.total_seconds() * 3600  # %/hour\n",
    "    return df\n",
    "\n",
    "# Define target (e.g., next AQI)\n",
    "def add_targets(df):\n",
    "    df['target_aqi'] = df['aqi'].shift(-1)  # Next AQI value\n",
    "    return df\n",
    "\n",
    "# Main function to fetch, process, and save data to Feature Store\n",
    "def main():\n",
    "    raw_data = []\n",
    "    start_date = datetime.now() - timedelta(days=30)  # Fetch data for the last 30 days\n",
    "\n",
    "    # Loop over each day in the range\n",
    "    for i in range(30):\n",
    "        date = start_date + timedelta(days=i)\n",
    "        data = fetch_combined_data(CITY, date)\n",
    "        if data:\n",
    "            raw_data.append(data)\n",
    "        else:\n",
    "            print(f\"No data collected for {date}\")  # Indicate if no data was collected for a date\n",
    "\n",
    "        time.sleep(60)  # Wait 60 seconds between API calls to avoid hitting rate limits\n",
    "\n",
    "    # Debugging output for raw data\n",
    "    print(\"Raw data collected:\", raw_data)  # Check if raw_data is populated\n",
    "\n",
    "    # Convert raw data to DataFrame\n",
    "    df = pd.DataFrame(raw_data)\n",
    "    if df.empty:\n",
    "        print(\"No data available to process.\")\n",
    "        return\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Keep as datetime for feature generation\n",
    "\n",
    "    # Compute features and targets\n",
    "    df = add_time_features(df)\n",
    "    df = add_derived_features(df)\n",
    "    df = add_targets(df)\n",
    "\n",
    "    # Convert timestamp to string for compatibility with Hopsworks\n",
    "    df['timestamp'] = df['timestamp'].astype(str)\n",
    "\n",
    "    # Drop rows with NaN (from diff or shift operations)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Connect to Hopsworks\n",
    "    project = hopsworks.login(api_key_value=\"NzKsbygmeyP444mJ.xIpih1OWQwPuer5J6bFSo6wDCiTrPLsiMdk8l1ErXL77cuxMEkQ9tM0z2ambpVqy\")\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    # Define the feature group\n",
    "    feature_group = fs.get_or_create_feature_group(\n",
    "        name=\"aqi_weather_features\",\n",
    "        version=1,\n",
    "        description=\"AQI and weather data with derived and target features\",\n",
    "        primary_key=[\"timestamp\"],\n",
    "        online_enabled=True\n",
    "    )\n",
    "\n",
    "    # Save the DataFrame to the Feature Store\n",
    "    feature_group.insert(df)\n",
    "    print(\"Features successfully inserted into Hopsworks Feature Store.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cb7fcf-e534-4585-a3cf-b54c83d6df7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.5\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "print(hsfs.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4bc989-e1ed-4547-92c2-985c21243701",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' on line 8 (2193214477.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 26\u001b[1;36m\u001b[0m\n\u001b[1;33m    ]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '(' on line 8\n"
     ]
    }
   ],
   "source": [
    "# create a simple feature view\n",
    "feature_view = fs.create_feature_view(\n",
    "    name='aqiview',\n",
    "    query=query\n",
    ")\n",
    "\n",
    "# create a feature view with transformation and label\n",
    "feature_view = fs.create_feature_view(\n",
    "    name='aqiview',\n",
    "    query=query,\n",
    "labels = \n",
    "    [\"timestamp\"],\n",
    "    [\"aqi\"],\n",
    "    [\"dominant_pollutant\"],\n",
    "    [\"temperature\"],\n",
    "    [\"humidity\"],\n",
    "    [\"hour\"],\n",
    "    [\"day\"],\n",
    "    [\"month\"],\n",
    "    [\"day_of_week\"],\n",
    "    [\"season\"],\n",
    "    [\"aqi_change_rate\"],\n",
    "    [\"temp_change_rate\"],\n",
    "    [\"humidity_change_rate\"],\n",
    "    [\"target_aqi\"]\n",
    "]\n",
    "    transformation_functions={\n",
    "        \"amount\": fs.get_transformation_function(name=\"standard_scaler\", version=1)\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e3d5e-a118-401e-b9c1-aeee2d8cc178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 20:41:03,358 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-24 20:41:03,534 INFO: Initializing external client\n",
      "2025-01-24 20:41:03,534 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-24 20:41:05,878 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1200282\n",
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1200282/fs/1189960/fv/aqiview_simple/version/1\n",
      "Simple Feature View created successfully.\n"
     ]
    },
    {
     "ename": "FeatureStoreException",
     "evalue": "Please use the hopsworks_udf decorator when defining transformation functions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature View with Transformations and Labels created successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mcreate_feature_views\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mcreate_feature_views\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimple Feature View created successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Step 5: Create a feature view with transformations and labels\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m feature_view_with_transform \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_feature_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maqiview_with_transform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget_aqi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Define the target variable\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformation_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard_scaler\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhumidity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard_scaler\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maqi_change_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard_scaler\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemp_change_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard_scaler\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhumidity_change_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard_scaler\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature View with Transformations and Labels created successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hopsworks_common\\usage.py:246\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    245\u001b[0m     exception \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hopsworks_common\\usage.py:242\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# Call the original method\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hsfs\\feature_store.py:1637\u001b[0m, in \u001b[0;36mFeatureStore.create_feature_view\u001b[1;34m(self, name, query, version, description, labels, inference_helper_columns, training_helper_columns, transformation_functions, logging_enabled)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;129m@usage\u001b[39m\u001b[38;5;241m.\u001b[39mmethod_logger\n\u001b[0;32m   1532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_feature_view\u001b[39m(\n\u001b[0;32m   1533\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1544\u001b[0m     logging_enabled: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1545\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m feature_view\u001b[38;5;241m.\u001b[39mFeatureView:\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a feature view metadata object and saved it to hopsworks.\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m \n\u001b[0;32m   1548\u001b[0m \u001b[38;5;124;03m    !!! example\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;124;03m        `FeatureView`: The feature view metadata object.\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1637\u001b[0m     feat_view \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureView\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeaturestore_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_helper_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_helper_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_helper_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_helper_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformation_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformation_functions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeaturestore_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_view_engine\u001b[38;5;241m.\u001b[39msave(feat_view)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hsfs\\feature_view.py:159\u001b[0m, in \u001b[0;36mFeatureView.__init__\u001b[1;34m(self, name, query, featurestore_id, id, version, description, labels, inference_helper_columns, training_helper_columns, transformation_functions, featurestore_name, serving_keys, logging_enabled, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transformation_function \u001b[38;5;129;01min\u001b[39;00m transformation_functions:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transformation_function, TransformationFunction):\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_functions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 159\u001b[0m             \u001b[43mTransformationFunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeaturestore_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhopsworks_udf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformation_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtransformation_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTransformationType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL_DEPENDENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m         )\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformation_function\u001b[38;5;241m.\u001b[39mtransformation_type:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\hsfs\\transformation_function.py:77\u001b[0m, in \u001b[0;36mTransformationFunction.__init__\u001b[1;34m(self, featurestore_id, hopsworks_udf, version, id, transformation_type, type, items, count, href, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_function_engine \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     72\u001b[0m     transformation_function_engine\u001b[38;5;241m.\u001b[39mTransformationFunctionEngine(\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_featurestore_id\n\u001b[0;32m     74\u001b[0m     )\n\u001b[0;32m     75\u001b[0m )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hopsworks_udf, HopsworksUdf):\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use the hopsworks_udf decorator when defining transformation functions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hopsworks_udf: HopsworksUdf \u001b[38;5;241m=\u001b[39m hopsworks_udf\n\u001b[0;32m     82\u001b[0m TransformationFunction\u001b[38;5;241m.\u001b[39m_validate_transformation_type(\n\u001b[0;32m     83\u001b[0m     transformation_type\u001b[38;5;241m=\u001b[39mtransformation_type, hopsworks_udf\u001b[38;5;241m=\u001b[39mhopsworks_udf\n\u001b[0;32m     84\u001b[0m )\n",
      "\u001b[1;31mFeatureStoreException\u001b[0m: Please use the hopsworks_udf decorator when defining transformation functions."
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "def create_feature_views():\n",
    "    # Step 1: Connect to Hopsworks\n",
    "    project = hopsworks.login(api_key_value=\"NzKsbygmeyP444mJ.xIpih1OWQwPuer5J6bFSo6wDCiTrPLsiMdk8l1ErXL77cuxMEkQ9tM0z2ambpVqy\")\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    # Step 2: Retrieve the feature group\n",
    "    feature_group = fs.get_feature_group(\"aqi_weather_features\", version=1)\n",
    "\n",
    "    # Step 3: Define the query\n",
    "    query = feature_group.select_all()\n",
    "\n",
    "    # Step 4: Create a simple feature view\n",
    "    feature_view_simple = fs.create_feature_view(\n",
    "        name='aqiview_simple',\n",
    "        query=query\n",
    "    )\n",
    "    print(\"Simple Feature View created successfully.\")\n",
    "\n",
    " \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_feature_views()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0916a934-3286-4a9c-92d5-5412e7d80a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy your Api Key (first register/login): https://c.app.hopsworks.ai/account/api/generated\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Paste it here:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 20:40:45,413 INFO: Initializing external client\n",
      "2025-01-24 20:40:45,413 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-24 20:40:49,101 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1200282\n",
      "Successfully connected to Hopsworks!\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import hsfs\n",
    "\n",
    "# Test connection\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "print(\"Successfully connected to Hopsworks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515565a5-1ac1-42dd-8c9d-e865c85799af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 21:04:59,393 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-24 21:04:59,412 INFO: Initializing external client\n",
      "2025-01-24 21:04:59,413 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-24 21:05:01,972 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1200282\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.34s) \n",
      "Data from Simple Feature View:\n",
      "                    timestamp  aqi dominant_pollutant  temperature  humidity  \\\n",
      "0  2025-01-20 22:27:42.717600  174               pm25         17.9        34   \n",
      "1  2025-01-20 22:25:40.121891  174               pm25         17.9        34   \n",
      "2  2025-01-20 22:22:35.157212  174               pm25         17.9        34   \n",
      "3  2025-01-20 22:21:33.861252  174               pm25         17.9        34   \n",
      "4  2025-01-20 22:20:31.747064  174               pm25         17.9        34   \n",
      "\n",
      "   hour  day  month  day_of_week  season  aqi_change_rate  temp_change_rate  \\\n",
      "0    22   20      1            0       1              0.0               0.0   \n",
      "1    22   20      1            0       1              0.0               0.0   \n",
      "2    22   20      1            0       1              0.0               0.0   \n",
      "3    22   20      1            0       1              0.0               0.0   \n",
      "4    22   20      1            0       1              0.0               0.0   \n",
      "\n",
      "   humidity_change_rate  target_aqi  \n",
      "0                   0.0       174.0  \n",
      "1                   0.0       174.0  \n",
      "2                   0.0       174.0  \n",
      "3                   0.0       174.0  \n",
      "4                   0.0       174.0  \n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "def read_simple_feature_view():\n",
    "    # Step 1: Connect to Hopsworks\n",
    "    project = hopsworks.login(api_key_value=\"NzKsbygmeyP444mJ.xIpih1OWQwPuer5J6bFSo6wDCiTrPLsiMdk8l1ErXL77cuxMEkQ9tM0z2ambpVqy\")\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    # Step 2: Retrieve the simple feature view\n",
    "    feature_view_simple = fs.get_feature_view(name=\"aqiview_simple\", version=1)\n",
    "\n",
    "    # Step 3: Read the data from the feature view\n",
    "    df = feature_view_simple.get_batch_data()\n",
    "\n",
    "    # Step 4: Print or process the data\n",
    "    print(\"Data from Simple Feature View:\")\n",
    "    print(df.head())  # Display the first few rows of the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    read_simple_feature_view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dac30de4-8b50-4d9f-9231-ef417d409f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 21:11:03,391 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-01-24 21:11:03,405 INFO: Initializing external client\n",
      "2025-01-24 21:11:03,406 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-01-24 21:11:06,094 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1200282\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.77s) \n",
      "Mean Squared Error: 3.884537500000017\n",
      "Model saved as 'aqi_prediction_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs import connection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "def train_pipeline():\n",
    "    # Step 1: Connect to Hopsworks and fetch data\n",
    "    project = hopsworks.login(api_key_value=\"NzKsbygmeyP444mJ.xIpih1OWQwPuer5J6bFSo6wDCiTrPLsiMdk8l1ErXL77cuxMEkQ9tM0z2ambpVqy\")\n",
    "    fs = project.get_feature_store()\n",
    "\n",
    "    # Load the feature group\n",
    "    feature_group = fs.get_feature_group(\"aqi_weather_features\", version=1)\n",
    "\n",
    "    # Fetch the data as a DataFrame using fetch()\n",
    "   # Fetch the data as a DataFrame using read()\n",
    "    df = feature_group.read()\n",
    "\n",
    "    # Step 2: Prepare the Data\n",
    "    # Drop the target and timestamp columns\n",
    "    X = df.drop(columns=['target_aqi', 'timestamp'])\n",
    "    y = df['target_aqi']\n",
    "\n",
    "    # Handle non-numeric columns\n",
    "    X_numeric = X.select_dtypes(include=['number'])  # Select only numeric columns\n",
    "\n",
    "    # Fill missing values with the mean\n",
    "    X_numeric = X_numeric.fillna(X_numeric.mean())\n",
    "\n",
    "    # Step 3: Split the Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_numeric, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 4: Select and Train a Model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Step 5: Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "    # Step 6: Save the Model\n",
    "    joblib.dump(model, 'aqi_prediction_model.pkl')\n",
    "    print(\"Model saved as 'aqi_prediction_model.pkl'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4748d6f-dbc3-4a5d-a727-23963ea8bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(api_key_value=\"qm82d9bpdrGwcAj0.q4qnhHm9W6nIcrSeMC5BKWuFW89XQ3N1u1oSlTZit8OOKRoDwTIDHhQoSllqZjjE\")\n",
    "\n",
    "# Access the Model Registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Save your trained model locally if not already done\n",
    "import joblib\n",
    "joblib.dump(model, \"aqi_prediction_model.pkl\")\n",
    "\n",
    "# Define metadata for the model\n",
    "input_schema = {\"features\": list(X.columns)}  # Replace with your feature names\n",
    "output_schema = {\"target\": \"target_aqi\"}     # Replace with your target variable name\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "# Register the model in the registry\n",
    "hopsworks_model = mr.tensorflow.create_model(\n",
    "    name=\"aqi_prediction_model\",\n",
    "    description=\"A model for predicting air quality index (AQI).\",\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "# Save the model files to the registry\n",
    "hopsworks_model.save(\"./\")  # Specify the directory containing the model file\n",
    "\n",
    "print(\"Model registered successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606dbe42-e9cb-41cc-9653-3d7c5f01724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import hsml  # Import the hsml library\n",
    "from hsml.model_schema import ModelSchema  # Import ModelSchema from hsml\n",
    "\n",
    "# Log in to your Hopsworks project\n",
    "project = hopsworks.login(api_key_value=\"qm82d9bpdrGwcAj0.q4qnhHm9W6nIcrSeMC5BKWuFW89XQ3N1u1oSlTZit8OOKRoDwTIDHhQoSllqZjjE\")\n",
    "\n",
    "# Set the Hopsworks connection for hsml - this is done automatically upon login\n",
    "# No need to manually call hsml.connection.connection().set_instance(project)\n",
    "\n",
    "# Access the Model Registry directly through the project object\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Now you can use 'mr' to interact with the Model Registry\n",
    "\n",
    "input_schema = {\n",
    "    \"features\": [\n",
    "        \"timestamp\",\n",
    "        \"aqi\",\n",
    "        \"dominant_pollutant\",\n",
    "        \"temperature\",\n",
    "        \"humidity\",\n",
    "        \"hour\",\n",
    "        \"day\",\n",
    "        \"month\",\n",
    "        \"day_of_week\",\n",
    "        \"season\",\n",
    "        \"aqi_change_rate\",\n",
    "        \"temp_change_rate\",\n",
    "        \"humidity_change_rate\"\n",
    "    ]\n",
    "}  # Replace with your feature names\n",
    "\n",
    "output_schema = {\"target\": \"target_aqi\"}  # Replace with your target variable name\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "# Register the model in the registry\n",
    "hopsworks_model = mr.sklearn.create_model(\n",
    "    name=\"aqi_prediction_model\",\n",
    "    description=\"A model for predicting air quality index (AQI).\",\n",
    "    model_schema=model_schema\n",
    ")\n",
    "\n",
    "# Save the model files to the registry\n",
    "hopsworks_model.save(\".\")  # Save the model to the registry\n",
    "print(\"Model registered successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af32544-5e8e-4a97-86c0-7dbdc68afc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hopsworks\n",
    "\n",
    "# Log in to your Hopsworks project\n",
    "project = hopsworks.login(api_key_value=\"qm82d9bpdrGwcAj0.q4qnhHm9W6nIcrSeMC5BKWuFW89XQ3N1u1oSlTZit8OOKRoDwTIDHhQoSllqZjjE\")\n",
    "\n",
    "# Get the model registry\n",
    "model_registry = project.get_model_registry()\n",
    "\n",
    "# Retrieve the model from the registry\n",
    "model_name = \"aqi_prediction_model\"  # Change to your model name\n",
    "model_version = 1  # Update the version if necessary\n",
    "model = model_registry.get_model(model_name, version=model_version)\n",
    "\n",
    "# Step 1: Download the latest model\n",
    "model.download()\n",
    "\n",
    "\n",
    "# For demonstration, we'll just print that the model is deployed\n",
    "print(\"Model deployed successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79179159-e486-4b55-b8ce-3d06f7470799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e61f3-ae44-4c9a-ae58-cc833e611fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import requests_cache\n",
    "from retrying import retry\n",
    "\n",
    "def fetch_aqi_data():\n",
    "    today = datetime.utcnow()\n",
    "    two_years_ago = today - timedelta(days=2 * 365)\n",
    "    current_unix_time = int(today.timestamp())\n",
    "    unix_start = int(two_years_ago.timestamp())\n",
    "\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/air_pollution/history?lat=24.8546842&lon=67.0207055&start={unix_start}&end={current_unix_time}&appid=c78b17200559431652d643ad3e0259a9\"\n",
    "    response = requests.get(url)\n",
    "    raw = response.json()\n",
    "    aqi_df = pd.json_normalize(raw[\"list\"])\n",
    "    aqi_df['dt'] = pd.to_datetime(aqi_df['dt'], unit='s')\n",
    "    aqi_df.set_index('dt', inplace=True)\n",
    "    aqi_df.index = aqi_df.index.tz_localize(None)\n",
    "    return aqi_df\n",
    "\n",
    "def fetch_weather_data():\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=3600)\n",
    "    start_date = datetime.utcnow() - timedelta(days=2 * 365)\n",
    "    end_date = datetime.utcnow() - timedelta(days=1)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": 24.8546842,\n",
    "        \"longitude\": 67.0207055,\n",
    "        \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"wind_speed_10m\"],\n",
    "        \"start_date\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"end_date\": end_date.strftime(\"%Y-%m-%d\"),\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    weather_data = response.json()\n",
    "    weather_df = pd.DataFrame(weather_data[\"hourly\"])\n",
    "    weather_df[\"time\"] = pd.to_datetime(weather_df[\"time\"])\n",
    "    weather_df.set_index(\"time\", inplace=True)\n",
    "    return weather_df\n",
    "\n",
    "# Combine AQI and weather data\n",
    "aqi_data = fetch_aqi_data()\n",
    "weather_data = fetch_weather_data()\n",
    "combined_data = aqi_data.join(weather_data, how=\"inner\")\n",
    "combined_data.reset_index(inplace=True)\n",
    "\n",
    "# Add additional features\n",
    "combined_data.index = pd.to_datetime(combined_data.index)\n",
    "\n",
    "# Extract time-related features\n",
    "combined_data[\"hour\"] = combined_data.index.hour\n",
    "combined_data[\"day\"] = combined_data.index.day\n",
    "combined_data[\"month\"] = combined_data.index.month\n",
    "combined_data[\"day_of_week\"] = combined_data.index.dayofweek\n",
    "combined_data[\"season\"] = combined_data[\"month\"].apply(lambda x: (x % 12 + 3) // 3)\n",
    "combined_data[\"aqi_change_rate\"] = combined_data[\"main.aqi\"].diff()\n",
    "\n",
    "# Calculate temperature and humidity change rates\n",
    "combined_data[\"temp_change_rate\"] = combined_data[\"temperature_2m\"].diff()\n",
    "combined_data[\"humidity_change_rate\"] = combined_data[\"relative_humidity_2m\"].diff()\n",
    "\n",
    "# Define features and target\n",
    "X = combined_data[[  # Ensure all required columns exist\n",
    "    \"hour\", \"day\", \"month\", \"day_of_week\", \"season\",\n",
    "    \"main.aqi\", \"temperature_2m\", \"relative_humidity_2m\",\n",
    "    \"aqi_change_rate\", \"temp_change_rate\", \"humidity_change_rate\"\n",
    "]]\n",
    "y = combined_data[\"main.aqi\"].shift(-1).fillna(method=\"ffill\")  # Predict next AQI\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model locally\n",
    "joblib.dump(model, \"aqi_model.pkl\")\n",
    "\n",
    "import hopsworks\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "project = hopsworks.login(api_key_value=\"qm82d9bpdrGwcAj0.q4qnhHm9W6nIcrSeMC5BKWuFW89XQ3N1u1oSlTZit8OOKRoDwTIDHhQoSllqZjjE\")\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Define input and output schemas\n",
    "input_schema = {\n",
    "    \"features\": [\n",
    "        \"hour\", \"day\", \"month\", \"day_of_week\", \"season\",\n",
    "        \"main.aqi\", \"temperature_2m\", \"relative_humidity_2m\",\n",
    "        \"aqi_change_rate\", \"temp_change_rate\", \"humidity_change_rate\"\n",
    "    ]\n",
    "}\n",
    "output_schema = {\"target\": \"Predicted AQI\"}\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "# Register and save the model\n",
    "hopsworks_model = mr.sklearn.create_model(\n",
    "    name=\"aqi_prediction_model\",\n",
    "    description=\"A model for predicting AQI based on historical data.\",\n",
    "    model_schema=model_schema\n",
    ")\n",
    "hopsworks_model.save(\"aqi_model.pkl\")\n",
    "print(\"Model registered successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd123ab7-93fb-400e-9530-4f690f784564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"aqi_model.pkl\")\n",
    "\n",
    "# Create the DataFrame from the provided data\n",
    "data = {\n",
    "    \"timestamp\": [\n",
    "        \"51:28.2\", \"52:28.9\", \"53:29.6\", \"54:30.2\", \"55:31.0\",\n",
    "        \"56:31.7\", \"57:32.4\", \"58:33.2\", \"43:27.4\", \"44:28.2\",\n",
    "        \"45:28.8\", \"46:29.5\", \"47:30.1\", \"48:30.9\", \"49:31.6\",\n",
    "        \"50:32.4\"\n",
    "    ],\n",
    "    \"aqi\": [124] * 16,\n",
    "    \"dominant_pollutant\": [\"pm25\"] * 16,\n",
    "    \"temperature\": [24.9, 24.9, 24.9, 24.9, 24.9, 24.9, 24.9, 24.9, 20.9, 19.9, 20.9, 19.9, 20.9, 20.9, 19.9, 19.9],\n",
    "    \"humidity\": [14, 14, 14, 14, 14, 14, 14, 14, 16, 17, 16, 17, 16, 16, 17, 17],\n",
    "    \"target_aqi\": [124] * 16\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adjust the timestamp format from MM:SS.s to 00:MM:SS.s\n",
    "df['timestamp'] = df['timestamp'].apply(lambda x: '00:' + x)\n",
    "\n",
    "# Convert the timestamp to timedelta\n",
    "df['timestamp'] = pd.to_timedelta(df['timestamp'])\n",
    "\n",
    "# Set the timestamp as the index\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Create a combined DataFrame to extract additional features\n",
    "combined_data = df.copy()\n",
    "\n",
    "# Extract time-related features from the index\n",
    "combined_data[\"hour\"] = combined_data.index.components['hours']\n",
    "combined_data[\"day\"] = combined_data.index.components['days']  # Use days as index is Timedelta\n",
    "combined_data[\"month\"] = 1  # Placeholder value for month (adjust as necessary)\n",
    "combined_data[\"day_of_week\"] = 4  # Placeholder value\n",
    "\n",
    "# Calculate the season based on the month (1-4 for the seasons)\n",
    "combined_data[\"season\"] = (combined_data[\"month\"] % 12 + 3) // 3\n",
    "\n",
    "# Calculate AQI change rate\n",
    "combined_data[\"aqi_change_rate\"] = combined_data[\"aqi\"].diff().fillna(0)  # Fill NaN with 0\n",
    "\n",
    "# Create missing features with placeholder values or calculations\n",
    "combined_data[\"humidity_change_rate\"] = combined_data[\"humidity\"].diff().fillna(0)\n",
    "combined_data[\"temp_change_rate\"] = combined_data[\"temperature\"].diff().fillna(0)\n",
    "\n",
    "# Prepare X_test - ensure it matches the trained model's feature names\n",
    "X_test = combined_data.drop(columns=[\"target_aqi\"])\n",
    "\n",
    "# Add the required features (make sure to match exactly what the model expects)\n",
    "X_test[\"month\"] = combined_data[\"month\"]\n",
    "\n",
    "# Rename the columns to match the trained model's expectations\n",
    "X_test.rename(columns={\n",
    "    \"aqi\": \"main.aqi\",\n",
    "    \"temperature\": \"temperature_2m\",\n",
    "    \"humidity\": \"relative_humidity_2m\",\n",
    "    \"hour\": \"hour\",\n",
    "    \"day\": \"day\",\n",
    "    \"day_of_week\": \"day_of_week\",\n",
    "    \"season\": \"season\",\n",
    "    \"aqi_change_rate\": \"aqi_change_rate\",\n",
    "    \"humidity_change_rate\": \"humidity_change_rate\",\n",
    "    \"temp_change_rate\": \"temp_change_rate\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Ensure the order of columns matches the trained model's expectations\n",
    "X_test = X_test[model.feature_names_in_]  # Use the feature names from the model directly\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Compare predictions with actual target values\n",
    "actual_aqi = combined_data[\"target_aqi\"].values\n",
    "comparison_df = pd.DataFrame({\"Actual AQI\": actual_aqi, \"Predicted AQI\": predictions})\n",
    "\n",
    "print(\"Comparison of Actual and Predicted AQI:\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb41c81-f1c9-4b85-9666-e9b8e44d09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine AQI and weather data\n",
    "aqi_data = fetch_aqi_data()\n",
    "weather_data = fetch_weather_data()\n",
    "combined_data = aqi_data.join(weather_data, how=\"inner\")\n",
    "\n",
    "# Debugging: Check the columns of combined_data\n",
    "print(\"Columns in combined_data:\", combined_data.columns)\n",
    "\n",
    "# Reset the index to ensure 'dt' is accessible\n",
    "combined_data.reset_index(inplace=True)\n",
    "\n",
    "# Check the DataFrame after reset\n",
    "print(\"DataFrame after reset index:\\n\", combined_data.head())\n",
    "\n",
    "# Rename the 'index' column to 'dt' for clarity\n",
    "combined_data.rename(columns={'index': 'dt'}, inplace=True)\n",
    "\n",
    "# Filter for the last 3 days of data\n",
    "three_days_ago = datetime.utcnow() - timedelta(days=3)\n",
    "combined_data = combined_data[combined_data['dt'] >= three_days_ago]\n",
    "\n",
    "# Check the filtered DataFrame\n",
    "print(\"Filtered DataFrame:\\n\", combined_data)\n",
    "\n",
    "# Set the index back to 'dt' for further processing\n",
    "combined_data.set_index('dt', inplace=True)\n",
    "\n",
    "# Add additional features\n",
    "combined_data[\"hour\"] = combined_data.index.hour\n",
    "combined_data[\"day\"] = combined_data.index.day\n",
    "combined_data[\"month\"] = combined_data.index.month\n",
    "combined_data[\"day_of_week\"] = combined_data.index.dayofweek\n",
    "combined_data[\"season\"] = combined_data[\"month\"].apply(lambda x: (x % 12 + 3) // 3)\n",
    "combined_data[\"aqi_change_rate\"] = combined_data[\"main.aqi\"].diff()\n",
    "\n",
    "# Calculate temperature and humidity change rates\n",
    "combined_data[\"temp_change_rate\"] = combined_data[\"temperature_2m\"].diff()\n",
    "combined_data[\"humidity_change_rate\"] = combined_data[\"relative_humidity_2m\"].diff()\n",
    "\n",
    "# Define features and target\n",
    "X = combined_data[[\n",
    "    \"hour\", \"day\", \"month\", \"day_of_week\", \"season\",\n",
    "    \"main.aqi\", \"temperature_2m\", \"relative_humidity_2m\",\n",
    "    \"aqi_change_rate\", \"temp_change_rate\", \"humidity_change_rate\"\n",
    "]]\n",
    "y = combined_data[\"main.aqi\"].shift(-1).fillna(method=\"ffill\")  # Predict next AQI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d781e-6734-4c10-8f38-ff429c87675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"aqi_model.pkl\")\n",
    "\n",
    "# Load the training data (you might need to adjust the path)\n",
    "combined_data = pd.read_csv('training_data.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X = combined_data[[  # Ensure all required columns exist\n",
    "    \"hour\", \"day\", \"month\", \"day_of_week\", \"season\",\n",
    "    \"main.aqi\", \"temperature_2m\", \"relative_humidity_2m\",\n",
    "    \"aqi_change_rate\", \"temp_change_rate\", \"humidity_change_rate\"\n",
    "]]\n",
    "y_true = combined_data[\"main.aqi\"].shift(-1).ffill()  # Actual AQI (shifted and filled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Remove the last entry from y_true to match lengths\n",
    "y_true = y_true[:-1]\n",
    "y_pred = y_pred[:-1]\n",
    "\n",
    "# Evaluate performance metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_true.index, y_true, label='Actual AQI', color='blue')\n",
    "plt.plot(y_true.index, y_pred, label='Predicted AQI', color='orange', linestyle='--')\n",
    "plt.title('Actual vs Predicted AQI')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('AQI')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279fab3b-451c-449c-a7ee-a057b1e4f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"aqi_model.pkl\")\n",
    "\n",
    "# Load the training data (adjust the path as needed)\n",
    "combined_data = pd.read_csv('training_data.csv', index_col='index', parse_dates=True)\n",
    "\n",
    "# Filter to get only the last 3 days of data\n",
    "latest_data = combined_data.last('3D')\n",
    "\n",
    "# Prepare features and target\n",
    "X = latest_data[[  # Ensure all required columns exist\n",
    "    \"hour\", \"day\", \"month\", \"day_of_week\", \"season\",\n",
    "    \"main.aqi\", \"temperature_2m\", \"relative_humidity_2m\",\n",
    "    \"aqi_change_rate\", \"temp_change_rate\", \"humidity_change_rate\"\n",
    "]]\n",
    "\n",
    "y_true = latest_data[\"main.aqi\"].shift(-1).ffill()  # Actual AQI (shifted and filled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Remove the last entry from y_true and y_pred to match lengths\n",
    "y_true = y_true[:-1]\n",
    "y_pred = y_pred[:-1]\n",
    "\n",
    "# Evaluate performance metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(latest_data.index[:-1], y_true, label='Actual AQI', color='blue')  # Use index for actual values\n",
    "plt.plot(latest_data.index[:-1], y_pred, label='Predicted AQI', color='orange', linestyle='--')  # Use index for predicted values\n",
    "plt.title('Actual vs Predicted AQI (Last 3 Days)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('AQI')\n",
    "\n",
    "# Set date format on the x-axis\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))  # Format to show only the date\n",
    "\n",
    "# Optional: Set locator for the x-axis to show every nth date (adjust as needed)\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=1))  # Show every day\n",
    "\n",
    "plt.xticks(rotation=45)  # Rotate x-axis ticks for better visibility\n",
    "plt.legend()\n",
    "plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
